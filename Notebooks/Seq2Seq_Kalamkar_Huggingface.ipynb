{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQuqH-sSclsQ",
        "outputId": "e73fdb04-7ba1-4019-c3ec-adbd8e6d5f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqZasNE_dD41"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainingArguments, Trainer, DataCollator\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmxNeMVWIbz8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVgE-FgrIzAg",
        "outputId": "b91f2ae9-3fd7-4752-b928-c95cfac1e0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CSYB_QIIqBl",
        "outputId": "249ac942-d097-4362-b4ac-462bf67d377a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Seq2Seq\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Seq2Seq/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfrJp5vVq3e"
      },
      "source": [
        "### Create Data for Hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZUZs77Hdjck"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXur0oRmIxwz"
      },
      "outputs": [],
      "source": [
        "train_path = 'train.json'\n",
        "dev_path = 'dev.json'\n",
        "train_data_raw = json.load(open(train_path))\n",
        "dev_data_raw = json.load(open(dev_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_n4ipqfJAsf"
      },
      "outputs": [],
      "source": [
        "train_sentences_list = list()\n",
        "train_labels_list = list()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xW1IMok5u_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aidcefm-JJu_"
      },
      "outputs": [],
      "source": [
        "def create_sentence_and_labels_list(data_raw):\n",
        "  len_data_raw = len(data_raw)\n",
        "  sentences = list()\n",
        "  labels = list()\n",
        "  for i in range(len_data_raw):\n",
        "    doc_len = len(data_raw[i]['annotations'][0]['result'])\n",
        "    for j in range(doc_len):\n",
        "      sent = data_raw[i]['annotations'][0]['result'][j]['value']['text']\n",
        "      label = data_raw[i]['annotations'][0]['result'][j]['value']['labels'][0]\n",
        "      sentences.append(sent)\n",
        "      labels.append(label)\n",
        "  \n",
        "  return sentences, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NCS88jbJCuj"
      },
      "outputs": [],
      "source": [
        "train_sentences_list, train_labels_list = create_sentence_and_labels_list(train_data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR0qMNI8tLt0"
      },
      "outputs": [],
      "source": [
        "dev_sentences_list, dev_labels_list = create_sentence_and_labels_list(dev_data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMk8SYAzJG8J"
      },
      "outputs": [],
      "source": [
        "#train_sentences_list[54]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_tuE_1-f0e5",
        "outputId": "2d5408d1-d05a-4700-af19-ccd1cb1c21fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = \"t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D02wX1Kqh4WJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7qTasT_jdMj"
      },
      "outputs": [],
      "source": [
        "#a = tokenizer(\"[156D-E](3) The fact that the amount realised is in excess of\\nthe tax leviable and not as amount which was not at all\\npayable as tax, would not make any difference.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJoHLEq4i1wn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr2_B4ghhXoc"
      },
      "outputs": [],
      "source": [
        "class TrainingDataset(Dataset):\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.x = train_sentences_list\n",
        "    self.y = train_labels_list\n",
        "    self.n_samples = len(train_sentences_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_ids = tokenizer(self.x[index])['input_ids']\n",
        "    label_ids = tokenizer(self.y[index])['input_ids']\n",
        "    return {\"input_ids\":input_ids,\"labels\":label_ids}\n",
        "  \n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtLrw-mKs9at"
      },
      "outputs": [],
      "source": [
        "class DevDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.x = dev_sentences_list\n",
        "    self.y = dev_labels_list\n",
        "    self.n_samples = len(dev_sentences_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_ids = tokenizer(self.x[index])['input_ids']\n",
        "    label_ids = tokenizer(self.y[index])['input_ids']\n",
        "    return {\"input_ids\":input_ids,\"labels\":label_ids} \n",
        "\n",
        "  \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlbuB4iBsyWb"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6BBEDg-jWj9"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-seq2seq-labeling\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate = 4e-3,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    weight_decay = 0.01,\n",
        "    save_total_limit = 1,\n",
        "    save_strategy=\"no\",\n",
        "    num_train_epochs = 10,\n",
        "    predict_with_generate = True,\n",
        "    push_to_hub = False,\n",
        "    load_best_model_at_end=False,\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model = model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "tdjo-2FLsgSg",
        "outputId": "409c804b-463d-44ad-dc21-77f165c28c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 28986\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 36240\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12026' max='36240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12026/36240 56:14 < 1:53:15, 3.56 it/s, Epoch 3.32/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.388300</td>\n",
              "      <td>0.413660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.405400</td>\n",
              "      <td>0.446413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.391100</td>\n",
              "      <td>0.420851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2879\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2879\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2879\n",
            "  Batch size = 8\n"
          ]
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=TrainingDataset(),\n",
        "    eval_dataset=DevDataset(),\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4DaaKjstjTQ"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Seq2Seq/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Outputs"
      ],
      "metadata": {
        "id": "Gw3vMtzlxTJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import TextClassificationPipeline\n",
        "devdataset = DevDataset()"
      ],
      "metadata": {
        "id": "_jqYBgimvChI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "c34cKgAAznN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "VRT188sI5Dpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_tokenize(txt):\n",
        "    doc = nlp(txt)\n",
        "    tokens = list(doc)\n",
        "    clean_tokens = []\n",
        "    for t in tokens:\n",
        "        if t.pos_ == 'PUNCT':\n",
        "            pass\n",
        "        elif t.pos_ == '\\n' or t.pos == '\\n\\n':\n",
        "          pass\n",
        "        elif t.pos_ == 'NUM':\n",
        "            clean_tokens.append(f'<NUM{len(t)}>')\n",
        "        else:    \n",
        "            lower_case = t.lemma_\n",
        "            clean_tokens.append(lower_case)\n",
        "    return clean_tokens"
      ],
      "metadata": {
        "id": "T_MLdArA5Cka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = list()\n",
        "for i in range(len(devdataset)):\n",
        "  data = devdataset.__getitem__(i)\n",
        "  x = data['input_ids']\n",
        "  y = data['labels']\n",
        "  pred = model.generate(input_ids = torch.tensor(x).to(device).view(1,-1))\n",
        "  #print(pred.shape)\n",
        "  pred_decoded = spacy_tokenize(tokenizer.decode(pred.squeeze(0)))\n",
        "  pred_decoded_clean = pred_decoded[3][:-3]\n",
        "  #print(pred_decoded)\n",
        "  preds.append(pred_decoded_clean)\n",
        "  \n"
      ],
      "metadata": {
        "id": "4YlYSnZxxGNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrNTtdgc4Suv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HusQmOG30lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_name = 'pred_t5_16_10.json'"
      ],
      "metadata": {
        "id": "PI3WtMIU4kLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pred_name, 'a') as jsonfile:\n",
        "      json.dump(preds, jsonfile)"
      ],
      "metadata": {
        "id": "jpFjNRt0xQn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_weighted = f1_score(dev_labels_list, preds, average='weighted')\n",
        "f1_macro = f1_score(dev_labels_list, preds, average='macro')\n",
        "f1_micro = f1_score(dev_labels_list, preds, average='micro')"
      ],
      "metadata": {
        "id": "VbEv9QX90hus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Weighted AVG F1: '+str(f1_weighted))\n",
        "print('Macro AVG F1: '+str(f1_macro))\n",
        "print('Micro AVG F1: '+str(f1_micro))"
      ],
      "metadata": {
        "id": "Sgq4Rlvk7JU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFm1pN7c77z9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq_Kalamkar_Huggingface.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}