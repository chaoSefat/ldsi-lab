{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxBC5TJyqQsl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuzGc6Ctomm9",
    "outputId": "a6461235-b8cc-4e18-adc4-e05486290dfa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWyrW0T5p1bk"
   },
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlwrbZN3p9lz",
    "outputId": "7bb5240c-c28f-48bd-eaf5-7469883d0d68"
   },
   "outputs": [],
   "source": [
    "%cd 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZzItLC1tR93"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po7ir-WCqMxU"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaFxovWRqDH4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(directory_in_str):\n",
    "  directory = os.fsencode(directory_in_str)\n",
    "  sentences = list()\n",
    "  labels = list()  \n",
    "  for file in os.listdir(directory):\n",
    "      filename = os.fsdecode(file)\n",
    "      with open(filename) as file:\n",
    "        print(filename)\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        for i in range(len(lines)):\n",
    "          a = lines[i].split('\\t')\n",
    "          sent = a[0]\n",
    "          label = a[1]\n",
    "          sentences.append(sent)\n",
    "          labels.append(label)\n",
    "      file.close()\n",
    "\n",
    "  return sentences, labels\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNAsb4cSLGJ5",
    "outputId": "bdb7b587-87fe-4eea-c78b-745d7d6843ca"
   },
   "outputs": [],
   "source": [
    "%cd '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/pretrained_embeddings/train'\n",
    "directory_in_str = '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/pretrained_embeddings/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOlFeXIAs_-g",
    "outputId": "839b7179-e73b-445c-cd9f-f71e6ebca0ae"
   },
   "outputs": [],
   "source": [
    "train_sentences, train_labels = preprocess(directory_in_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyoEjjgHyAoM",
    "outputId": "1d43985f-fa17-4da7-b709-9e113756d1ef"
   },
   "outputs": [],
   "source": [
    "#irectory_in_str = '/content/drive/MyDrive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/text/dev'\n",
    "directory_in_str = '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/text/dev'\n",
    "%cd '/content/drive/My Drive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/text/dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqNOM05pyGvV"
   },
   "outputs": [],
   "source": [
    "#%cd '/content/drive/MyDrive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/text/dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgOg3GVj0EgM",
    "outputId": "ef055d11-5ec3-4324-e03c-c2aa60434007"
   },
   "outputs": [],
   "source": [
    "dev_sentences, dev_labels = preprocess(directory_in_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJnC7_O00U4l"
   },
   "source": [
    "## Saving Data into Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bGel1KY0LEA"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('train_sentences.json', 'a') as jsonfile:\n",
    "      json.dump(train_sentences, jsonfile)\n",
    "with open('train_labels.json', 'a') as jsonfile:\n",
    "      json.dump(train_labels, jsonfile)   \n",
    "with open('dev_sentences.json', 'a') as jsonfile:\n",
    "      json.dump(dev_sentences, jsonfile)\n",
    "with open('dev_labels.json', 'a') as jsonfile:\n",
    "      json.dump(dev_labels, jsonfile)   \n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xovY41Mw0PYW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIO1SEwb00rO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "448Et5ni03Nw",
    "outputId": "4b5e2df5-51f1-43b5-e6c3-c93081aa949c"
   },
   "outputs": [],
   "source": [
    "train_sentences = json.load(open('train_sentences.json'))\n",
    "train_labels = json.load(open('train_labels.json'))\n",
    "dev_sentences = json.load(open('dev_sentences.json'))\n",
    "dev_labels = json.load(open('dev_labels.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMtVYkv04zYy"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPRb_8FN42V5"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainingArguments, Trainer, DataCollator\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRScv9CI49U7"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYNUGJTB5HRH"
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.x = train_sentences\n",
    "    self.y = train_labels\n",
    "    self.n_samples = len(train_sentences)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.n_samples\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    input_ids = tokenizer(self.x[index])['input_ids']\n",
    "    label_ids = tokenizer(self.y[index])['input_ids']\n",
    "    return {\"input_ids\":input_ids,\"labels\":label_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRr5rjNJ5RMl"
   },
   "outputs": [],
   "source": [
    "class DevDataset(Dataset):\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.x = dev_sentences\n",
    "    self.y = dev_labels\n",
    "    self.n_samples = len(dev_sentences)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.n_samples\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    input_ids = tokenizer(self.x[index])['input_ids']\n",
    "    label_ids = tokenizer(self.y[index])['input_ids']\n",
    "    return {\"input_ids\":input_ids,\"labels\":label_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W809bjdz5axy"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR-jjEPY5l1H"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = 't5-small-paheli'\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-seq2seq-labeling\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = 2e-3,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    save_total_limit = 1,\n",
    "    save_strategy=\"no\",\n",
    "    num_train_epochs = 6,\n",
    "    predict_with_generate = True,\n",
    "    push_to_hub = False,\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sI9btkG15wQE"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=TrainingDataset(),\n",
    "    eval_dataset=DevDataset(),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7ufv6435xVy"
   },
   "outputs": [],
   "source": [
    "trainer.save_model('/content/drive/MyDrive/TUM/SS22/LDSI_LAB/Implementations/Paheli_data/text/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEtbH1fa5xj2"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsoJmuWG5xrp"
   },
   "outputs": [],
   "source": [
    "def spacy_tokenize(txt):\n",
    "    doc = nlp(txt)\n",
    "    tokens = list(doc)\n",
    "    clean_tokens = []\n",
    "    for t in tokens:\n",
    "        if t.pos_ == 'PUNCT':\n",
    "            pass\n",
    "        elif t.pos_ == '\\n' or t.pos == '\\n\\n':\n",
    "          pass\n",
    "        elif t.pos_ == 'NUM':\n",
    "            clean_tokens.append(f'<NUM{len(t)}>')\n",
    "        else:    \n",
    "            lower_case = t.lemma_\n",
    "            clean_tokens.append(lower_case)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRqPe2jXFAss"
   },
   "outputs": [],
   "source": [
    "devdataset = DevDataset()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcekEexPE56a"
   },
   "outputs": [],
   "source": [
    "dev_preds = list()\n",
    "for i in range(len(devdataset)):\n",
    "  data = devdataset.__getitem__(i)\n",
    "  x = data['input_ids']\n",
    "  y = data['labels']\n",
    "  pred = model.generate(input_ids = torch.tensor(x).to(device).view(1,-1))\n",
    "  pred_decoded = spacy_tokenize(tokenizer.decode(pred.squeeze(0)))\n",
    "  pred_decoded_clean = pred_decoded[3][:-3]\n",
    "  #print(pred_decoded_clean)\n",
    "  dev_preds.append(pred_decoded_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9KJk3FTGgsF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_weighted = f1_score(dev_labels, dev_preds, average='weighted')\n",
    "f1_macro = f1_score(dev_labels, dev_preds, average='macro')\n",
    "f1_micro = f1_score(dev_labels, dev_preds, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P45_W7NOFSNR"
   },
   "outputs": [],
   "source": [
    "print('Weighted AVG F1: '+str(f1_weighted))\n",
    "print('Macro AVG F1: '+str(f1_macro))\n",
    "print('Micro AVG F1: '+str(f1_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHEWK7E6G0A8"
   },
   "outputs": [],
   "source": [
    "### For training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhIuKUFgG3Hg"
   },
   "outputs": [],
   "source": [
    "traindataset = TrainingDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFyj_jEcG_PJ"
   },
   "outputs": [],
   "source": [
    "train_preds = list()\n",
    "for i in range(len(traindataset)):\n",
    "  data = traindataset.__getitem__(i)\n",
    "  x = data['input_ids']\n",
    "  y = data['labels']\n",
    "  pred = model.generate(input_ids = torch.tensor(x).to(device).view(1,-1))\n",
    "  pred_decoded = spacy_tokenize(tokenizer.decode(pred.squeeze(0)))\n",
    "  pred_decoded_clean = pred_decoded[3][:-3]\n",
    "  #print(pred_decoded_clean)\n",
    "  train_preds.append(pred_decoded_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8xjznuSHEow"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_weighted = f1_score(train_labels, train_preds, average='weighted')\n",
    "f1_macro = f1_score(train_labels, train_preds, average='macro')\n",
    "f1_micro = f1_score(train_labels, train_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtB4ZZWVIEoT"
   },
   "outputs": [],
   "source": [
    "print('Weighted AVG F1: '+str(f1_weighted))\n",
    "print('Macro AVG F1: '+str(f1_macro))\n",
    "print('Micro AVG F1: '+str(f1_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UW1oxj-yLTyJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Paheli_Hugging_Face.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
